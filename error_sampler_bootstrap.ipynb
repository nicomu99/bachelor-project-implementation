{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Based Test using Bootstrapping On the Error Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "\n",
    "sys.path.append('/home/nico/VSCodeRepos/SigMA')\n",
    "from NoiseRemoval.xd_special import XDSingleCluster\n",
    "from miscellaneous.covariance_trafo_sky2gal import transform_covariance_shper2gal\n",
    "from miscellaneous.error_sampler import ErrorSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided by Sebastian Ratzenb√∂ck\n",
    "data_gaia = pd.read_csv('simulated_data/data_orion_focus.csv')\n",
    "\n",
    "# Simulate a Gaussian cluster in 6D\n",
    "cols = ['X', 'Y', 'Z', 'U', 'V', 'W']\n",
    "mu_true = data_gaia[cols].median().values # is this supposed to be median or mean?\n",
    "C_true = np.diag([25, 25, 25, 4, 4, 4])\n",
    "N = 1000\n",
    "\n",
    "data = np.random.multivariate_normal(mu_true, C_true, N)\n",
    "df = pd.DataFrame(data, columns=[cols])\n",
    "\n",
    "cols2match = [\n",
    "    'ra_error', 'dec_error', 'parallax_error', 'pmra_error', 'pmdec_error', 'radial_velocity_error',\n",
    "    'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
    "    'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr'\n",
    "]\n",
    "\n",
    "ra, dec, plx, pmra, pmdec, rv = ErrorSampler().cart2spher(df[cols].values)\n",
    "df['ra'] = ra\n",
    "df['dec'] = dec\n",
    "df['parallax'] = plx\n",
    "df['pmra'] = pmra\n",
    "df['pmdec'] = pmdec\n",
    "df['radial_velocity'] = rv\n",
    "\n",
    "df[cols2match] = data_gaia[cols2match].sample(n=N, replace=True).values\n",
    "df.loc[df['radial_velocity_error'].isna().values.ravel(), 'radial_velocity_error'] = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first shuffle then split the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_right = df[:len(df) // 2]\n",
    "df_left = df[len(df) // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the two covariance matrices and the mean\n",
    "def get_xd(data_):\n",
    "    err_sampler = ErrorSampler(data_)\n",
    "    err_sampler.build_covariance_matrix()\n",
    "    # Create sample from errors\n",
    "    data_new = pd.DataFrame(err_sampler.spher2cart(err_sampler.new_sample()), columns=cols)\n",
    "    c_vel = ['U', 'V', 'W']\n",
    "    X = data_new[c_vel]\n",
    "    C = err_sampler.C[:, 3:, 3:]\n",
    "    C.shape\n",
    "    ra, dec, plx, _, _, _ = ErrorSampler().cart2spher(data_new[cols].values)\n",
    "    # Compute covariance matrix in Galactic coordinates\n",
    "    C_uvw = transform_covariance_shper2gal(ra, dec, plx, C)     \n",
    "    xd = XDSingleCluster(max_iter=200, tol=1e-3).fit(X.values, C_uvw)\n",
    "    return xd, err_sampler, data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd, err_sampler, data_new = get_xd(df_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_test(data1, data2):\n",
    "    _, err_sampler_left = get_xd(data1)\n",
    "    _, err_sampler_right = get_xd(data2)\n",
    "\n",
    "    # generate a sample from both distributions\n",
    "    diffs = []\n",
    "    for i in range(100):\n",
    "        # get a sample from both samplers\n",
    "        sampeled_data_left = err_sampler_left.spher2cart(err_sampler_left.new_sample())\n",
    "        sampled_data_right = err_sampler_right.spher2cart(err_sampler_right.new_sample())\n",
    "        diffs.append(np.mean(sampeled_data_left[:, [3, 4, 5]], axis=0) - np.mean(sampled_data_right[:, [3, 4, 5]], axis=0))\n",
    "\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative parallax values encountered, fixing values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-98.67252184, -40.13147028, -32.79344073],\n",
       "       [ 87.78673641,  37.47595832,  29.41664599]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = perform_test(df_left, df_right)\n",
    "np.percentile(diffs, [2.5, 97.5], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
