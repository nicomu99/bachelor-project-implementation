{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "sys.path.append('/home/nico/VSCodeRepos/SigMA/')\n",
    "from SigMA.SigMA import SigMA\n",
    "from miscellaneous.error_sampler import ErrorSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#plt_colors = [\n",
    "#    '#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3',\n",
    "#    '#FF6692', '#B6E880', '#FF97FF', '#FECB52', '#B82E2E', '#316395'\n",
    "#]\n",
    "\n",
    "def plot_3D_data(data, xyz_titles=['X', 'Y', 'Z'], ax_range=[-40, 40], labels=None, true_labels=None):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=1,\n",
    "        specs=[[{\"type\": \"scatter3d\"}]],\n",
    "        column_widths=[1],\n",
    "        subplot_titles=[\n",
    "            '3D', \n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # if true labels is not none, get rid of cluster -1\n",
    "    if true_labels is not None:\n",
    "        data = data.loc[true_labels != -1]\n",
    "        # true_labels = true_labels[true_labels != -1]\n",
    "        labels = labels[true_labels != -1]\n",
    "    print(np.unique(labels, return_counts=True))\n",
    "\n",
    "    # --------------- 3D scatter plot -------------------\n",
    "    if labels is None:\n",
    "        trace_3d = go.Scatter3d(\n",
    "            x=data.loc[:, xyz_titles[0]], y=data.loc[:, xyz_titles[1]], z=data.loc[:, xyz_titles[2]],\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color='red'),\n",
    "            hoverinfo='none',\n",
    "            showlegend=False,\n",
    "        )\n",
    "        fig.add_trace(trace_3d, row=1, col=1)\n",
    "    else:\n",
    "        for l_i in np.unique(labels):\n",
    "            if l_i != -1:\n",
    "                trace_3d = go.Scatter3d(\n",
    "                    x=data.loc[labels==l_i, xyz_titles[0]], y=data.loc[labels==l_i, xyz_titles[1]], z=data.loc[labels==l_i, xyz_titles[2]],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=5),\n",
    "                    hoverinfo='none',\n",
    "                    showlegend=True,\n",
    "                    name=f'Cluster {l_i}'\n",
    "                )\n",
    "                fig.add_trace(trace_3d, row=1, col=1)\n",
    "    \n",
    "    # 3d position\n",
    "    plt_kwargs = dict(showbackground=False, showline=False, zeroline=True, zerolinecolor='grey', zerolinewidth=2, \n",
    "                      showgrid=True, showticklabels=True, color='black',\n",
    "                      linecolor='black', linewidth=1,  gridcolor='rgba(100,100,100,0.5)')\n",
    "\n",
    "    xaxis=dict(**plt_kwargs, title=xyz_titles[0], range=ax_range)\n",
    "    yaxis=dict(**plt_kwargs, title=xyz_titles[1], range=ax_range)\n",
    "    zaxis=dict(**plt_kwargs, title=xyz_titles[2], range=ax_range)\n",
    "\n",
    "    # Finalize layout\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        #width=800,\n",
    "        #height=800,\n",
    "        showlegend=True,\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        legend= dict(itemsizing='constant', font_color='black'),\n",
    "        # 3D plot\n",
    "        scene=dict(\n",
    "            xaxis=dict(xaxis),\n",
    "            yaxis=dict(yaxis),\n",
    "            zaxis=dict(zaxis)\n",
    "        )\n",
    "    )\n",
    "    fig.write_html(f\"/home/nico/Desktop/evaluation_data/simulated_cluster_{'sigma' if true_labels is not None else 'true'}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self):\n",
    "        self.data_gaia = pd.read_csv('simulated_data/data_orion_focus.csv')\n",
    "        self.df_xyz = pd.read_csv('simulated_data/Simulated_clusters_labeled_Region0_run6.csv')\n",
    "        self.df_uvw = pd.read_csv('simulated_data/UVW_stats_region0_new.csv')\n",
    "\n",
    "        self.X_means = self.df_xyz.groupby('label').mean()[['X', 'Y', 'Z']]\n",
    "        # self.X_means['X_std'] = np.random.uniform(3, 8, size=len(self.X_means))\n",
    "        # self.X_means['Y_std'] = np.random.uniform(3, 8, size=len(self.X_means))\n",
    "        # self.X_means['Z_std'] = np.random.uniform(3, 8, size=len(self.X_means))\n",
    "        self.X_means['X_std'] = [3, 4, 5, 6, 7, 8]\n",
    "        self.X_means['Y_std'] = [3, 4, 5, 6, 7, 8]\n",
    "        self.X_means['Z_std'] = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "        new_idx = self.df_uvw.columns[1:]\n",
    "        new_cols = self.df_uvw['Cluster_id new'].values\n",
    "        self.df_uvw = pd.DataFrame(self.df_uvw[new_idx].T.values, columns=new_cols, index=new_idx).rename(\n",
    "            columns={'mean U': 'U', 'mean V': 'V', 'mean W': 'W', \n",
    "                'SD U': 'U_std', 'SD V': 'V_std', 'SD W': 'W_std'},\n",
    "        )\n",
    "\n",
    "        # for the first 6 clusters, add uvw info\n",
    "        self.df_infos = pd.concat((self.X_means, self.df_uvw.iloc[:6].reset_index(inplace=False, drop=True)), axis=1)\n",
    "        self.df_infos['U_std'] = 2\n",
    "        self.df_infos['V_std'] = 2\n",
    "        self.df_infos['W_std'] = 2\n",
    "\n",
    "        self.df = None\n",
    "        self.labels = None\n",
    "\n",
    "    def generate_data(self, test_cases):\n",
    "        mu_cols_position = ['X', 'Y', 'Z']\n",
    "        mu_cols_velocity = ['U', 'V', 'W']\n",
    "        std_cols = ['U_std', 'V_std', 'W_std']\n",
    "        data_simulated = []\n",
    "        self.labels = []\n",
    "\n",
    "        # generate data for each cluster\n",
    "        cluster_id = 0\n",
    "        \"\"\" for i in range(self.df_infos.shape[0]):\n",
    "            mu_position = self.df_infos[mu_cols_position].iloc[i].values # get the means for each cluster, position\n",
    "            mu_velocity = self.df_infos[mu_cols_velocity].iloc[i].values # get the means for each cluster, velocity\n",
    "            std = self.df_infos[std_cols].iloc[i].values # get the std for each cluster\n",
    "            N = max(int(self.df_infos[['n_cluster']].iloc[i].values), 200) // 2 # either 50 or n_cluster\n",
    "            C = np.diag(std**2) # covariance matrix with variance on diagonal\n",
    "            # create one cluster with the means of position and velocity, and covariance matrix\n",
    "            cluster_simulated = [np.random.multivariate_normal(np.concatenate((mu_position, mu_velocity)), C, N)] # generate N samples from multivariate normal\n",
    "            # add another part of the cluster using shifted position means\n",
    "            mu_position = mu_position + (np.ones(3) * shift_mean_val[i] * shift_direction[i])\n",
    "            cluster_simulated.append(np.random.multivariate_normal(np.concatenate((mu_position, mu_velocity)), C, N))\n",
    "            cluster_simulated = np.vstack(cluster_simulated) # stack all data\n",
    "            data_simulated.append(cluster_simulated) # generate N samples from multivariate normal\n",
    "            self.labels.append(np.ones(N * 2, dtype=int)*cluster_id) # add labels\n",
    "            cluster_id += 1 \"\"\"\n",
    "\n",
    "        for test_case in test_cases:\n",
    "            for labels, mu_position, mu_std in zip(test_case['clusters'], test_case['mu_position'], test_case['mu_std']):\n",
    "                mu_velocity = self.df_infos[mu_cols_velocity].iloc[labels].values\n",
    "                std = np.concatenate((mu_std, self.df_infos[std_cols].iloc[labels].values))\n",
    "                N = max(int(self.df_infos[['n_cluster']].iloc[labels].values), 200)\n",
    "                C = np.diag(std**2)\n",
    "                cluster_simulated = np.random.multivariate_normal(np.concatenate((mu_position, mu_velocity)), C, N)\n",
    "                data_simulated.append(cluster_simulated)\n",
    "                self.labels.append(np.ones(N, dtype=int)*cluster_id)\n",
    "                cluster_id += 1\n",
    "            \n",
    "        data_simulated = np.vstack(data_simulated) # stack all data\n",
    "        self.labels = np.hstack(self.labels) # stack all labels\n",
    "\n",
    "        # Simulate a Gaussian cluster in 6D\n",
    "        cols = ['X', 'Y', 'Z', 'U', 'V', 'W']\n",
    "        self.df = pd.DataFrame(data_simulated, columns=cols)\n",
    "\n",
    "        # Sample from the ErrorSampler\n",
    "        cols2match = [\n",
    "            'ra_error', 'dec_error', 'parallax_error', 'pmra_error', 'pmdec_error', 'radial_velocity_error',\n",
    "            'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
    "            'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr'\n",
    "        ]\n",
    "        ra, dec, plx, pmra, pmdec, rv = ErrorSampler().cart2spher(self.df[cols].values)\n",
    "        self.df['ra'] = ra\n",
    "        self.df['dec'] = dec\n",
    "        self.df['parallax'] = plx\n",
    "        self.df['pmra'] = pmra\n",
    "        self.df['pmdec'] = pmdec\n",
    "        self.df['radial_velocity'] = rv\n",
    "\n",
    "        return self.df, self.labels\n",
    "        \n",
    "    def add_noise(self, n_samples=50_000):\n",
    "        cols = ['X', 'Y', 'Z', 'U', 'V', 'W']\n",
    "        cols2match = [\n",
    "            'ra_error', 'dec_error', 'parallax_error', 'pmra_error', 'pmdec_error', 'radial_velocity_error',\n",
    "            'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
    "            'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr'\n",
    "        ]\n",
    "        # Add bg noise\n",
    "        delta_perc = 50\n",
    "        ptp_data = self.df[cols].max() - self.df[cols].min()\n",
    "        ranges = [\n",
    "            (self.df[col].min() - ptp_data[col] * delta_perc, self.df[col].max() + ptp_data[col] * delta_perc) \n",
    "                for col in cols\n",
    "            ]\n",
    "        # Create uniform noise\n",
    "        noise = pd.DataFrame(np.random.uniform(*zip(*ranges), (n_samples, len(cols))), columns=cols)\n",
    "        ra, dec, plx, pmra, pmdec, rv = ErrorSampler().cart2spher(noise[cols].values)\n",
    "        noise['ra'] = ra\n",
    "        noise['dec'] = dec\n",
    "        noise['parallax'] = plx\n",
    "        noise['pmra'] = pmra\n",
    "        noise['pmdec'] = pmdec\n",
    "        noise['radial_velocity'] = rv\n",
    "        cols_shere = ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity']\n",
    "        # Add noise to data\n",
    "        self.df = pd.concat([self.df[cols + cols_shere], noise[cols + cols_shere]], axis=0)\n",
    "        self.labels = np.r_[self.labels, np.ones(n_samples) * -1].astype(int)\n",
    "\n",
    "        # Compute distances to cluster centers\n",
    "        dists = np.sqrt(np.sum(self.X_means.values**2, axis=1))\n",
    "        dx = 2\n",
    "        dmin, dmax = dists.min()-dx, dists.max()+dx \n",
    "        self.data_gaia['dist'] = np.sqrt(np.sum(self.data_gaia[['X', 'Y', 'Z']].values**2, axis=1))\n",
    "        self.data_gaia = self.data_gaia.loc[(self.data_gaia['dist'] > dmin) & (self.data_gaia['dist'] < dmax)]\n",
    "\n",
    "        # Keep only data within cluster range\n",
    "        self.df[cols2match] = self.data_gaia[cols2match].sample(n=self.df.shape[0], replace=True).values\n",
    "        self.df.loc[self.df['radial_velocity_error'].isna().values.ravel(), 'radial_velocity_error'] = 1e3\n",
    "\n",
    "        err_sampler = ErrorSampler(self.df)\n",
    "        err_sampler.build_covariance_matrix()\n",
    "        # Create sample from errors\n",
    "        data_new = pd.DataFrame(err_sampler.new_sample(), columns=cols_shere)\n",
    "        data_new_cart = pd.DataFrame(err_sampler.spher2cart(data_new.values), columns=cols)\n",
    "        data = pd.concat([data_new, data_new_cart, self.df[cols2match].reset_index(drop=True)], axis=1)\n",
    "\n",
    "        return data, self.labels\n",
    "\n",
    "    def run_error_sampler(self):\n",
    "        cols = ['X', 'Y', 'Z', 'U', 'V', 'W']\n",
    "        err_sampler = ErrorSampler(self.df)\n",
    "        err_sampler.build_covariance_matrix()\n",
    "        # Create sample from errors\n",
    "        data_new = pd.DataFrame(err_sampler.spher2cart(err_sampler.new_sample()), columns=cols)\n",
    "\n",
    "        return data_new, self.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative parallax values encountered, fixing values...\n"
     ]
    }
   ],
   "source": [
    "# contains true split\n",
    "test_case_1 = [\n",
    "    {\n",
    "        'clusters': [0, 1],\n",
    "        'mu_position': [\n",
    "            [-500, -500, 20],\n",
    "            [-490, -490, 30]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([3, 5, 2]),\n",
    "            np.array([4, 8, 2])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains true split\n",
    "test_case_2 = [\n",
    "    {\n",
    "        'clusters': [0, 2],\n",
    "        'mu_position': [\n",
    "            [20, 40, 150],\n",
    "            [20, 40, 150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([7, 3, 4]),\n",
    "            np.array([6, 5, 5])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains true split\n",
    "test_case_3 = [\n",
    "    {\n",
    "        'clusters': [0, 3],\n",
    "        'mu_position': [\n",
    "            [-20, 40, 160],\n",
    "            [-20, 40, 140]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([5, 7, 3]),\n",
    "            np.array([4, 5, 3])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains true split\n",
    "test_case_4 = [\n",
    "    {\n",
    "        'clusters': [0, 4],\n",
    "        'mu_position': [\n",
    "            [-20, 300, 160],\n",
    "            [-20, 300, 150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 3, 4]),\n",
    "            np.array([6, 5, 4])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains true split\n",
    "test_case_5 = [\n",
    "    {\n",
    "        'clusters': [0, 5],\n",
    "        'mu_position': [\n",
    "            [-20, 300, 170],\n",
    "            [-20, 300, 160]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 3, 4]),\n",
    "            np.array([6, 5, 4])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a few noise splits\n",
    "test_case_6 = [\n",
    "    {\n",
    "        'clusters': [1, 2],\n",
    "        'mu_position': [\n",
    "            [-30, -150, 180],\n",
    "            [-30, -150, 160]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 2, 4]),\n",
    "            np.array([6, 6, 4])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a true split\n",
    "test_case_7 = [\n",
    "    {\n",
    "        'clusters': [1, 3],\n",
    "        'mu_position': [\n",
    "            [-30, 150, 180],\n",
    "            [-30, 150, 160]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([5, 7, 7]),\n",
    "            np.array([4, 4, 7])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a true split\n",
    "test_case_8 = [\n",
    "    {\n",
    "        'clusters': [1, 4],\n",
    "        'mu_position': [\n",
    "            [200, -150, 0],\n",
    "            [200, -170, 0]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([3, 3, 3]),\n",
    "            np.array([7, 7, 7])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a true split\n",
    "test_case_9 = [\n",
    "    {\n",
    "        'clusters': [1, 5],\n",
    "        'mu_position': [\n",
    "            [100, 200, -150],\n",
    "            [100, 200, -150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([3, 3, 3]),\n",
    "            np.array([7, 7, 7])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a true split\n",
    "test_case_10 = [\n",
    "    {\n",
    "        'clusters': [2, 3],\n",
    "        'mu_position': [\n",
    "            [-100, 200, -150],\n",
    "            [-100, 200, -150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 4, 3]),\n",
    "            np.array([7, 5, 7])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a true split and 2 noise splits\n",
    "test_case_11 = [\n",
    "    {\n",
    "        'clusters': [2, 4],\n",
    "        'mu_position': [\n",
    "            [-100, 300, -150],\n",
    "            [-100, 300, -150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([7, 7, 7]),\n",
    "            np.array([7, 7, 7])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains 5 noise spilts\n",
    "test_case_12 = [\n",
    "    {\n",
    "        'clusters': [2, 5],\n",
    "        'mu_position': [\n",
    "            [-100, 400, -150],\n",
    "            [-100, 400, -150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([3, 3, 3]),\n",
    "            np.array([3, 3, 3])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a few noise splits\n",
    "test_case_13 = [\n",
    "    {\n",
    "        'clusters': [3, 4],\n",
    "        'mu_position': [\n",
    "            [270, 200, 300],\n",
    "            [270, 200, 300]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 3, 7]),\n",
    "            np.array([4, 5, 5])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# contains a few noise splits\n",
    "test_case_14 = [\n",
    "    {\n",
    "        'clusters': [3, 5],\n",
    "        'mu_position': [\n",
    "            [260, -100, 200],\n",
    "            [260, -100, 200]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 3, 7]),\n",
    "            np.array([4, 5, 6])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_15 = [\n",
    "    {\n",
    "        'clusters': [0, 0],\n",
    "        'mu_position': [\n",
    "            [260, -90, 200],\n",
    "            [260, -115, 200]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 3, 7]),\n",
    "            np.array([4, 5, 6])\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_16 = [\n",
    "    {\n",
    "        'clusters': [1, 1],\n",
    "        'mu_position': [\n",
    "            [120, 20, 200],\n",
    "            [120, -10, 200]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([5, 7, 7]),\n",
    "            np.array([4, 7, 7])\n",
    "        ]   \n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_17 = [\n",
    "    {\n",
    "        'clusters': [2, 2],\n",
    "        'mu_position': [\n",
    "            [400, 400, 400],\n",
    "            [360, 400, 400]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([7, 7, 4]),\n",
    "            np.array([7, 7, 4])\n",
    "        ]   \n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_18 = [\n",
    "    {\n",
    "        'clusters': [3, 3],\n",
    "        'mu_position': [\n",
    "            [400, 250, 400],\n",
    "            [400, 265, 400]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([3, 3, 3]),\n",
    "            np.array([3, 3, 3])\n",
    "        ]   \n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_19 = [\n",
    "    {\n",
    "        'clusters': [4, 4],\n",
    "        'mu_position': [\n",
    "            [-100, 250, 400],\n",
    "            [-127, 250, 400]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([4, 6, 7]),\n",
    "            np.array([4, 2, 5])\n",
    "        ]   \n",
    "    }\n",
    "]\n",
    "\n",
    "# can contain a wrong split\n",
    "test_case_20 = [\n",
    "    {\n",
    "        'clusters': [5, 5],\n",
    "        'mu_position': [\n",
    "            [200, -350, 150],\n",
    "            [230, -350, 150]\n",
    "        ],\n",
    "        'mu_std': [\n",
    "            np.array([7, 5, 4]),\n",
    "            np.array([3, 3, 5])\n",
    "        ]   \n",
    "    }\n",
    "]\n",
    "\n",
    "# total about:\n",
    "# - 10 true splits\n",
    "# - 10 noise splits\n",
    "# - 5 wrong splits\n",
    "\n",
    "# combine the test cases\n",
    "test_cases = test_case_1 + test_case_2 + test_case_3 + test_case_4 + test_case_5 + test_case_6 + test_case_7 + test_case_8 + test_case_9 + test_case_10 + test_case_11 + test_case_12 + test_case_13 + test_case_14 + test_case_15 + test_case_16 + test_case_17 + test_case_18 + test_case_19 + test_case_20\n",
    "\n",
    "data_generator = DataGenerator()\n",
    "data_generator.generate_data(test_cases)\n",
    "data, labels_true = data_generator.add_noise(n_samples=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "       16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
      "       33, 34, 35, 36, 37, 38, 39]), array([50000,   305,   438,   305,   200,   305,  3965,   305,   274,\n",
      "         305,   200,   438,   200,   438,  3965,   438,   274,   438,\n",
      "         200,   200,  3965,   200,   274,   200,   200,  3965,   274,\n",
      "        3965,   200,   305,   305,   438,   438,   200,   200,  3965,\n",
      "        3965,   274,   274,   200,   200]))\n"
     ]
    }
   ],
   "source": [
    "cols = ['X', 'Y', 'Z']\n",
    "# cols = ['ra', 'dec', 'parallax']\n",
    "# cols = ['U', 'V', 'W']\n",
    "# cols = ['pmra', 'pmdec', 'radial_velocity']\n",
    "plot_3D_data(data, xyz_titles=cols, ax_range=[-1000, 1000], labels=labels_true, true_labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting SigMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gradient ascend using a 15-NN density estimation.\n",
      "Updated significance threshold: 2.93e-04\n"
     ]
    }
   ],
   "source": [
    "cols2fit = ['ra', 'dec', 'parallax', 'pmra', 'pmdec']\n",
    "df_fit = copy.deepcopy(data[cols2fit])\n",
    "# Scale features\n",
    "sf = {\n",
    "    'ra': 1/0.64,\n",
    "    'dec': 1/0.65,\n",
    "    'parallax': 1/0.15,\n",
    "    'pmra': 1/0.49,\n",
    "    'pmdec': 1/0.57\n",
    "}\n",
    "for col in cols2fit:\n",
    "    df_fit[col] *= sf[col]\n",
    "\n",
    "sigma_kwargs = dict(\n",
    "    cluster_features=cols2fit,\n",
    "    scale_factors=None,\n",
    "    # These are the default values and should be kept for now\n",
    "    nb_resampling=0, max_knn_density=101,\n",
    "    beta=0.99, knn_initcluster_graph=40,\n",
    "    transform_function=None\n",
    ")\n",
    "clusterer = SigMA(data=df_fit, **sigma_kwargs).fit(alpha=0.01, knn=15, bh_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  439,   915,  1194,  1518,  1970,  5681,  6009,  6442,  7035,\n",
      "        7053, 11127, 11885, 12412, 12795, 13410, 17343, 17738, 17849,\n",
      "       18469, 23039, 26290, 27676, 27997, 28204, 33392, 36385, 36567,\n",
      "       36810, 37096]), array([ 743,  305,  198,  277, 3995,  616,  269,  199,  439,  199, 4403,\n",
      "        712,  438,  200, 4171,  467,  201,  200, 4240, 4576,  199,  876,\n",
      "        206,  194, 7929,  259,  289,  189,  211]))\n"
     ]
    }
   ],
   "source": [
    "plot_3D_data(data, xyz_titles=cols, ax_range=[-1000, 1000], labels=clusterer.labels_, true_labels=labels_true)\n",
    "# plot_3D_data(data, xyz_titles=cols, ax_range=[-1000, 1000], labels=clusterer.labels_, true_labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_baseline(clusterer):\n",
    "    _, p_values = clusterer.run_sigma(\n",
    "        alpha=-np.inf, knn=15, return_pvalues=True\n",
    "    )\n",
    "    p_values = np.array(p_values)\n",
    "    pv_sorted = np.sort(p_values[p_values < 0.05])\n",
    "    # compute mid point betw*een consecutive p-values\n",
    "    mid_points = (pv_sorted[1:] + pv_sorted[:-1]) / 2\n",
    "    return mid_points, clusterer.labels_\n",
    "\n",
    "mid_points, l0 = produce_baseline(clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration count: 57\n",
      "iteration 1\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 2\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 3\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 4\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 5\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 6\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 7\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 8\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 9\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 10\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 11\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 12\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 13\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 14\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 15\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 16\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 17\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 18\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 19\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 20\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 21\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 22\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 23\n",
      "No new cluster\n",
      "-------------------\n",
      "\n",
      "iteration 24\n",
      "New cluster: 70978 coming from 28204\n",
      "True labels new cluster: (array([-1]), array([16769]))\n",
      "True labels old cluster: (array([-1, 32, 33]), array([123, 200, 200]))\n",
      "-------------------\n",
      "\n",
      "iteration 25\n",
      "New cluster: 27997 coming from 28204\n",
      "True labels new cluster: (array([-1, 32, 33]), array([ 50, 200,   6]))\n",
      "True labels old cluster: (array([-1, 33]), array([ 73, 194]))\n",
      "-------------------\n",
      "\n",
      "iteration 26\n",
      "New cluster: 1518 coming from 1970\n",
      "True labels new cluster: (array([-1,  2,  4,  5]), array([  1,   1, 274,   2]))\n",
      "True labels old cluster: (array([-1,  3,  4,  5]), array([   6,    1,   31, 3963]))\n",
      "-------------------\n",
      "\n",
      "iteration 27\n",
      "New cluster: 6009 coming from 5681\n",
      "True labels new cluster: (array([-1,  6,  7]), array([ 64,   6, 263]))\n",
      "True labels old cluster: (array([-1,  6,  7,  8,  9]), array([ 20, 299,  11, 305,   1]))\n",
      "-------------------\n",
      "\n",
      "iteration 28\n",
      "New cluster: 54689 coming from 37096\n",
      "True labels new cluster: (array([-1]), array([7306]))\n",
      "True labels old cluster: (array([-1, 38, 39]), array([ 60, 200, 200]))\n",
      "-------------------\n",
      "\n",
      "iteration 29\n",
      "New cluster: 61083 coming from 439\n",
      "True labels new cluster: (array([-1]), array([6615]))\n",
      "True labels old cluster: (array([-1,  0,  1]), array([16546,   305,   438]))\n",
      "-------------------\n",
      "\n",
      "iteration 30\n",
      "New cluster: 49673 coming from 439\n",
      "True labels new cluster: (array([-1]), array([7342]))\n",
      "True labels old cluster: (array([-1,  0,  1]), array([9204,  305,  438]))\n",
      "-------------------\n",
      "\n",
      "iteration 31\n",
      "New cluster: 36810 coming from 37096\n",
      "True labels new cluster: (array([-1, 38]), array([  6, 189]))\n",
      "True labels old cluster: (array([-1, 38, 39]), array([ 54,  11, 200]))\n",
      "-------------------\n",
      "\n",
      "iteration 32\n",
      "New cluster: 13052 coming from 13410\n",
      "True labels new cluster: (array([-1, 18, 19]), array([  5, 158,  11]))\n",
      "True labels old cluster: (array([-1, 18, 19, 20, 21]), array([  11,   42, 3954,    2,    4]))\n",
      "-------------------\n",
      "\n",
      "iteration 33\n",
      "New cluster: 17370 coming from 17343\n",
      "True labels new cluster: (array([-1, 20, 21]), array([  5,   8, 247]))\n",
      "True labels old cluster: (array([-1, 20, 21]), array([  2, 189,  23]))\n",
      "-------------------\n",
      "\n",
      "iteration 34\n",
      "New cluster: 86389 coming from 70978\n",
      "True labels new cluster: (array([-1]), array([8909]))\n",
      "True labels old cluster: (array([-1]), array([7860]))\n",
      "-------------------\n",
      "\n",
      "iteration 35\n",
      "New cluster: 28557 coming from 33392\n",
      "True labels new cluster: (array([-1, 34, 35]), array([ 210, 3825,  122]))\n",
      "True labels old cluster: (array([-1, 24, 34, 35]), array([  94,    7,  140, 3835]))\n",
      "-------------------\n",
      "\n",
      "iteration 36\n",
      "New cluster: 44027 coming from 439\n",
      "True labels new cluster: (array([-1]), array([6543]))\n",
      "True labels old cluster: (array([-1,  0,  1]), array([2661,  305,  438]))\n",
      "-------------------\n",
      "\n",
      "iteration 37\n",
      "New cluster: 39644 coming from 86389\n",
      "True labels new cluster: (array([-1]), array([98]))\n",
      "True labels old cluster: (array([-1]), array([8811]))\n",
      "-------------------\n",
      "\n",
      "iteration 38\n",
      "New cluster: 82652 coming from 70978\n",
      "True labels new cluster: (array([-1]), array([72]))\n",
      "True labels old cluster: (array([-1]), array([7788]))\n",
      "-------------------\n",
      "\n",
      "iteration 39\n",
      "New cluster: 65355 coming from 439\n",
      "True labels new cluster: (array([-1]), array([1868]))\n",
      "True labels old cluster: (array([-1,  0,  1]), array([793, 305, 438]))\n",
      "-------------------\n",
      "\n",
      "iteration 40\n",
      "New cluster: 44837 coming from 49673\n",
      "True labels new cluster: (array([-1]), array([56]))\n",
      "True labels old cluster: (array([-1]), array([7286]))\n",
      "-------------------\n",
      "\n",
      "iteration 41\n",
      "New cluster: 54251 coming from 86389\n",
      "True labels new cluster: (array([-1]), array([693]))\n",
      "True labels old cluster: (array([-1]), array([8118]))\n",
      "-------------------\n",
      "\n",
      "iteration 42\n",
      "New cluster: 60378 coming from 49673\n",
      "True labels new cluster: (array([-1]), array([754]))\n",
      "True labels old cluster: (array([-1]), array([6532]))\n",
      "-------------------\n",
      "\n",
      "iteration 43\n",
      "New cluster: 57688 coming from 49673\n",
      "True labels new cluster: (array([-1]), array([262]))\n",
      "True labels old cluster: (array([-1]), array([6270]))\n",
      "-------------------\n",
      "\n",
      "iteration 44\n",
      "New cluster: 60230 coming from 70978\n",
      "True labels new cluster: (array([-1]), array([150]))\n",
      "True labels old cluster: (array([-1]), array([7638]))\n",
      "-------------------\n",
      "\n",
      "iteration 45\n",
      "New cluster: 72511 coming from 70978\n",
      "True labels new cluster: (array([-1]), array([222]))\n",
      "True labels old cluster: (array([-1]), array([7416]))\n",
      "-------------------\n",
      "\n",
      "iteration 46\n",
      "New cluster: 59299 coming from 86389\n",
      "True labels new cluster: (array([-1]), array([122]))\n",
      "True labels old cluster: (array([-1]), array([7996]))\n",
      "-------------------\n",
      "\n",
      "iteration 47\n",
      "New cluster: 26974 coming from 23039\n",
      "True labels new cluster: (array([26, 29]), array([  3, 226]))\n",
      "True labels old cluster: (array([-1, 26, 27, 28, 29]), array([  19, 3962,    2,  304,   79]))\n",
      "-------------------\n",
      "\n",
      "iteration 48\n",
      "New cluster: 56008 coming from 61083\n",
      "True labels new cluster: (array([-1]), array([758]))\n",
      "True labels old cluster: (array([-1]), array([5857]))\n",
      "-------------------\n",
      "\n",
      "iteration 49\n",
      "New cluster: 74915 coming from 44027\n",
      "True labels new cluster: (array([-1]), array([354]))\n",
      "True labels old cluster: (array([-1]), array([6189]))\n",
      "-------------------\n",
      "\n",
      "iteration 50\n",
      "New cluster: 53404 coming from 65355\n",
      "True labels new cluster: (array([-1]), array([1149]))\n",
      "True labels old cluster: (array([-1]), array([719]))\n",
      "-------------------\n",
      "\n",
      "iteration 51\n",
      "New cluster: 38643 coming from 70978\n",
      "True labels new cluster: (array([-1]), array([45]))\n",
      "True labels old cluster: (array([-1]), array([7371]))\n",
      "-------------------\n",
      "\n",
      "iteration 52\n",
      "New cluster: 78253 coming from 54689\n",
      "True labels new cluster: (array([-1]), array([286]))\n",
      "True labels old cluster: (array([-1]), array([7020]))\n",
      "-------------------\n",
      "\n",
      "iteration 53\n",
      "New cluster: 43605 coming from 49673\n",
      "True labels new cluster: (array([-1]), array([93]))\n",
      "True labels old cluster: (array([-1]), array([6177]))\n",
      "-------------------\n",
      "\n",
      "iteration 54\n",
      "New cluster: 27103 coming from 27676\n",
      "True labels new cluster: (array([30, 31]), array([425,  10]))\n",
      "True labels old cluster: (array([-1, 30, 31]), array([  2,  13, 428]))\n",
      "-------------------\n",
      "\n",
      "iteration 55\n",
      "New cluster: 68125 coming from 86389\n",
      "True labels new cluster: (array([-1]), array([250]))\n",
      "True labels old cluster: (array([-1]), array([7746]))\n",
      "-------------------\n",
      "\n",
      "iteration 56\n",
      "New cluster: 70439 coming from 86389\n",
      "True labels new cluster: (array([-1]), array([3122]))\n",
      "True labels old cluster: (array([-1]), array([4624]))\n",
      "-------------------\n",
      "\n",
      "iteration 57\n",
      "New cluster: 68169 coming from 44027\n",
      "True labels new cluster: (array([-1]), array([1162]))\n",
      "True labels old cluster: (array([-1]), array([5027]))\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = {}\n",
    "clusterer_labels = pd.DataFrame({f'iteration_0': l0})\n",
    "print(f'iteration count: {len(mid_points)}')\n",
    "iteration = 1\n",
    "for alpha_i in mid_points:\n",
    "    # fit clusterer to new alpha\n",
    "    clusterer = clusterer.fit(alpha=alpha_i, knn=15, bh_correction=False)\n",
    "    print(f'iteration {iteration}')\n",
    "\n",
    "    l_i = clusterer.labels_\n",
    "    new_clusters_id = list(set(l_i) - set(l0))\n",
    "    clusterer_labels[f'iteration_{iteration}'] = l_i\n",
    "\n",
    "    if len(new_clusters_id) == 1: \n",
    "        # one new cluster was generated\n",
    "        nc_id = new_clusters_id[0]\n",
    "        part_of_old_cluster = mode(l0[l_i==nc_id], keepdims=False).mode\n",
    "        print(f'New cluster: {nc_id} coming from {part_of_old_cluster}')\n",
    "        splits[f'iteration_{iteration}'] = {\n",
    "            'new_cluster': nc_id,\n",
    "            'old_cluster': part_of_old_cluster,\n",
    "            'alpha': alpha_i\n",
    "        }\n",
    "\n",
    "        # print the true labels of the new cluster\n",
    "        print(f'True labels new cluster: {np.unique(labels_true[l_i==nc_id], return_counts=True)}')\n",
    "        print(f'True labels old cluster: {np.unique(labels_true[l_i==part_of_old_cluster], return_counts=True)}')\n",
    "        \n",
    "    elif len(new_clusters_id) > 1:\n",
    "        print('More than one new cluster')\n",
    "    else:\n",
    "        print('No new cluster')\n",
    "\n",
    "    iteration += 1\n",
    "    l0 = np.copy(l_i)\n",
    "    print('-------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dense_sample(rho):\n",
    "    \"\"\"Extract the densest points from the density distribution.\"\"\"\n",
    "    mad = np.median(np.abs(rho - np.median(rho)))\n",
    "    threshold = np.median(rho) * 0.995 + 3 * mad * 1.1\n",
    "    if np.sum(rho > threshold) < 20:\n",
    "        threshold = np.percentile(rho, 93)\n",
    "    return rho > threshold\n",
    "\n",
    "# plotting the clustered labels according to their true cluster\n",
    "for split in splits:\n",
    "    old_cluster = splits[split]['old_cluster']\n",
    "    new_cluster = splits[split]['new_cluster']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    for i, cluster in enumerate([old_cluster, new_cluster]):\n",
    "        # get the dense core\n",
    "        rho = clusterer.weights_[clusterer_labels[split] == cluster]\n",
    "        dense_core = dense_sample(rho)\n",
    "        # plot the dense core\n",
    "        label, counts = np.unique(labels_true[clusterer_labels[split] == cluster][dense_core], return_counts=True)\n",
    "        ax[i].bar(label, counts)\n",
    "\n",
    "    plt.close()\n",
    "    fig.savefig(f'/home/nico/Desktop/split_{split}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   12,   720,  3110,  4054,  5105,  5345,  5610,  5763,  6081,\n",
      "        6156,  7979,  9011, 10026, 10450, 10572, 10712, 10786, 10948,\n",
      "       11108, 11304, 11518, 12430, 15769, 15900, 16005, 16046]), array([ 390,  212, 2188, 2427,   83,   80,  108,  363,  224,   58,  121,\n",
      "        395, 3787,  124,   72,  128,  168,  161,  212,  202,  197, 3970,\n",
      "        128,  130,  114,   98]))\n"
     ]
    }
   ],
   "source": [
    "cols = ['X', 'Y', 'Z']\n",
    "# cols = ['ra', 'dec', 'plx']\n",
    "# cols = ['U', 'V', 'W']\n",
    "# cols = ['pmra', 'pmdec', 'radial_velocity']\n",
    "plot_3D_data(df, xyz_titles=cols, ax_range=[-600, 600], labels=clusterer.labels_, true_labels=labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
